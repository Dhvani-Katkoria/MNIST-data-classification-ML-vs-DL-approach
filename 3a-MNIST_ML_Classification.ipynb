{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()  #load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hog = []\n",
    "for trainfeature in x_train:\n",
    "    #feature extraction of training images\n",
    "    fd = hog(trainfeature.reshape((28,28)), orientations=9, pixels_per_cell=(7,7),cells_per_block=(1,1))   \n",
    "    train_hog.append(fd)\n",
    "hog_trainfeatures = np.array(train_hog, dtype=np.float64)\n",
    "\n",
    "test_hog = []\n",
    "for testfeature in x_test:\n",
    "    #feature extraction of test images\n",
    "    fd = hog(testfeature.reshape((28,28)), orientations=9, pixels_per_cell=(7,7),cells_per_block=(1,1))\n",
    "    test_hog.append(fd)\n",
    "hog_testfeatures = np.array(test_hog, dtype=np.float64)\n",
    "# hog_testfeatures = np.array(test_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fca0e9f9610>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABaCAYAAADXaio8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEbUlEQVR4nO2dMUhkRxjHf1+UA8u7DcmGTUgiXKNBmyVYpT5TeCk1glcIwSJrJysELKzCaScptDhjQEybKw5CsEmbtVBPIblLIOTMmUu4QgNqEvxS7ObY9b1jX957fu929/vB4+38mTfz7Z9hZmdmd1ZUFceGl7IOoJNwsw1xsw1xsw1xsw1xsw1JZLaI3BCR70XkoYjMphVU26KqsS6gC/gR6AWuANtAX5NntEOu38Pef5KW/S7wUFV/UtW/gC+BmwnKayd+DhOTmF0AfqlLP6ppDYjIRyJSEZFKgrragu4Ez0qIFpj7q+oKsAIgIh29NpCkZT8C3qhLvw78miyc9iZJy/4OuC4ibwMHwCjwYSpRZcD8/HxDem5urmkegOXl5YB2cHAQWkdss1X1HxH5GPia6ieTO6q6F7e8TiBJy0ZV7wH3Uoql7fEZpCFutiFiuVNTKBR0amqqQTs+Pg7kW1hYuNQ4wt6zSNgn2dhsqWrxougt2xA32xA32xDTPruVpuuTk5MBrbe3N6B1dwc/PZfLZe+zs8bNNsTNNsTNNiTR2sj/pVAoMD093aCVy+XUyu/q6gpoo6OjAe3w8DCg5fP5hvTp6Wkgz/7+fkA7Pz+PHJ+3bEPcbEPcbEPcbENMZ5C5XE6Hh4cbtL294OZOf39/Q3poaCiQp1QqpRtcBJaWliLlK5VKPoPMGjfbEDfbEDfbENMBslgsaqXS+C20lLejUiPq1tzMzEyY7ANk1rjZhrjZhrjZhmS+BzkwMBDIt7Oz07SssAFsc3MzoJ2dnQW08fHxpuVvbW0FtPX19YB2dHQU+rgPkBnjZhviZhviZhuS+QAZRi6Xa0ivrq5GKn9kZCRSvotLuBC+1JsAHyCzxs02xM02xFf9EjI2NhbQNjY2vM/OGjfbEDfbkKZmi8gdEXkiIvfrtGsi8o2IPKjdr15umO1B0wFSRN4D/gS+UNV3atpt4Kmqflo71OWqqjb9hmQ+n9eJiYkUwg5f9RscHAxo29vbkcpbW1trmmd3dzegLS4uhmWNN0Cq6rfA0wvyTeC/6NaAD5qV48Tvs19V1ccAtfsr6YXUvlz6AFl/uMvJycllV/dCE9fs30TkNYDa/cnzMqrqiqoWVbXY09MTs7o2IeLhW28B9+vSC8Bs7fUscDtiOVkflGV1VULffwSDNoDHwN9UT8+ZBHLAJvCgdr/mZjc3+4Vcz24DfG0ka9xsQ0x/mgf8QfWAwZdrr1uVZvG/GSaa9tnPKhWphPVprULc+L0bMcTNNiQrs1cyqjctYsWfSZ/dqXg3YoibbYi52a12dH+a24KmZotIF/AZMAz0AWMi0mcZQww+B25c0GaBTVW9TnUhLlKjsW7ZLXd0f5rbgtZmRzq6vwWItS1obXako/vbFWuz2+Xo/sjbgvVYm/3s6H4RuUL16P67xjGkwV3gVu31LeCrSE/F/VOguBfwPvAD1T8U+sS6/hjxprYt6NN1Q3wGaYibbYibbYibbYibbYibbYibbci/nAfWGhJ2kRkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hog_trainfeatures.shape\n",
    "plt.subplot(1, 5, 1)\n",
    "# plt.imshow(np.reshape(x_train[0], (28,28)), cmap=plt.cm.gray)\n",
    "# plt.imshow(np.reshape(x_train[1], (28,28)), cmap=plt.cm.gray)\n",
    "# plt.imshow(np.reshape(x_train[2], (28,28)), cmap=plt.cm.gray)\n",
    "# plt.subplot(1, 5, 1)\n",
    "# plt.imshow(np.reshape(hog_trainfeatures[0], (12,12)), cmap=plt.cm.gray)\n",
    "plt.imshow(np.reshape(hog_trainfeatures[1], (12,12)), cmap=plt.cm.gray)\n",
    "# plt.imshow(np.reshape(hog_trainfeatures[2], (12,12)), cmap=plt.cm.gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processing by scaling of training images\n",
    "preProcess = preprocessing.MaxAbsScaler().fit(hog_trainfeatures)\n",
    "hog_train = preProcess.transform(hog_trainfeatures)\n",
    "\n",
    "#pre processing by scaling of test images\n",
    "preProcess = preprocessing.MaxAbsScaler().fit(hog_testfeatures)\n",
    "hog_test = preProcess.transform(hog_testfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vidhikatkoria/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vidhikatkoria/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic regression model for classification\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(hog_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9422\n"
     ]
    }
   ],
   "source": [
    "score = lr.score(hog_test, y_test)  # accuracy obtained\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate LBPH feature \n",
    "def getLocalBinaryPattern(img, points, radius):\n",
    "    lbp = feature.local_binary_pattern(img, points, radius, method=\"uniform\")\n",
    "    hist, _ = np.histogram(lbp.ravel(), \n",
    "                bins=np.arange(0, points + 3),\n",
    "                range=(0, points + 2))\n",
    "\n",
    "    return lbp, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate features for each image\n",
    "def formatDataset():\n",
    "#     (x_train, y_train), (x_test, y_test) = dataset\n",
    "\n",
    "    x_train_hst = []\n",
    "    for i in range(len(x_train)):\n",
    "        _, hst = getLocalBinaryPattern(x_train[i], 64, 2)\n",
    "#         print(\"Computing LBP for training set: {}/{}\".format(i, len(x_train)))\n",
    "        x_train_hst.append(hst)\n",
    "\n",
    "    print(\"Done computing LBP for training set!\")\n",
    "\n",
    "    x_test_hst=[]\n",
    "    for i in range(len(x_test)):\n",
    "        _, hst = getLocalBinaryPattern(x_test[i], 64, 2)\n",
    "#         print(\"Computing LBP for test set: {}/{}\".format(i, len(x_test)))\n",
    "        x_test_hst.append(hst)\n",
    "\n",
    "    print(\"Done computing LBP for test set!\")\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return x_train_hst, y_train, x_test_hst, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing LBP for training set!\n",
      "Done computing LBP for test set!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Extract features\n",
    "x_train_hst, y_train, x_test_hst, y_test = formatDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_hst = np.array(x_train_hst,dtype=np.float64)\n",
    "x_test_hst = np.array(x_test_hst,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vidhikatkoria/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vidhikatkoria/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training using logistic regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(x_train_hst, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5863\n"
     ]
    }
   ],
   "source": [
    "score = lr.score(x_test_hst, y_test) #accuracy obtained\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
